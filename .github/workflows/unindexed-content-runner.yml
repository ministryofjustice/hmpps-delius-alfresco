#
# Alfresco Unindexed Content Runner
#
# This GitHub Actions workflow automates the process of reindexing Alfresco content created or modified
# within a specified time window (in hours). It is run from the scheduler file.
#
# Workflow Overview:
# - Accepts environment and look-back window (in hours) as inputs.
# - Finds Alfresco documents within the specified time window.
# - Kicks off a reindex job to reindex the nodes.
---
name: "Alfresco: Unindexed Content Runner"

on:
  workflow_call:
    inputs:
      environment:
        description: "Target Environment"
        required: true
        type: string
      hours:
        description: "Look-back window in hours"
        required: true
        type: string

permissions:
  contents: read

jobs:
  find-and-reindex:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: ${{ inputs.environment }}
    environment: ${{ matrix.environment }}-preapproved

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install kubectl
        uses: azure/setup-kubectl@v4
        with:
          version: "v1.29.13"

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: "v3.15.2"

      - name: Install Task
        uses: arduino/setup-task@v2
        with:
          version: 3.x

      - name: Configure kubectl context
        run: |
          echo "${{ secrets.KUBE_CERT }}" > ca.crt
          kubectl config set-cluster ${KUBE_CLUSTER} --certificate-authority=./ca.crt --server="https://${KUBE_CLUSTER}"
          kubectl config set-credentials deploy-user --token="${{ secrets.KUBE_TOKEN }}"
          kubectl config set-context ${KUBE_CLUSTER} --cluster=${KUBE_CLUSTER} --user=deploy-user --namespace="${KUBE_NAMESPACE}"
          kubectl config use-context ${KUBE_CLUSTER}
        env:
          KUBE_NAMESPACE: ${{ secrets.KUBE_NAMESPACE }}
          KUBE_CLUSTER: ${{ secrets.KUBE_CLUSTER }}

      - name: Set vars
        id: vars
        shell: bash
        run: |
          set -euo pipefail
          ENV="${{ matrix.environment }}"
          NS="hmpps-delius-alfresco-${ENV}"
          # Preprod/prod spelling guard preserved if you use it in your repo; adjust if needed.
          if [[ "${ENV}" == "poc" ]]; then NS="hmpps-delius-alfrsco-${ENV}"; fi
          echo "ns=$NS" >> $GITHUB_OUTPUT
          echo "env=$ENV" >> $GITHUB_OUTPUT

      # --- helpers: find utils pod and retryable kubectl
      - name: Define helper functions
        id: helpers
        shell: bash
        run: |
          cat > helpers.sh <<'EOF'
          set -euo pipefail

          kubectl_retry() {
            local max_retries=5 delay=10 attempt=1
            while true; do
              if kubectl "$@"; then return 0; fi
              echo "kubectl failed (attempt $attempt/$max_retries): kubectl $*" >&2
              (( attempt >= max_retries )) && return 1
              attempt=$((attempt+1)); sleep $delay
            done
          }

          get_utils_pod() {
            local ns="$1"
            local pod
            pod=$(kubectl_retry -n "$ns" get pods -l app=utils -o name 2>/dev/null | head -n1 | cut -d/ -f2 || true)
            if [[ -z "$pod" ]]; then
              pod=$(kubectl_retry -n "$ns" get pods --no-headers -o custom-columns=":metadata.name" | grep -m1 -E 'utils' || true)
            fi
            printf "%s" "$pod"
          }

          sql_in_utils() {
            local ns="$1" q="$2"
            local pod; pod=$(get_utils_pod "$ns")
            [[ -z "$pod" ]] && { echo "No utils pod in $ns" >&2; exit 1; }
            local tmp=$(mktemp)
            cat >"$tmp" <<'EOS'
          #!/usr/bin/env bash
          [[ -f /etc/profile.d/psql-utils.sh ]] && . /etc/profile.d/psql-utils.sh || true
          psqlr --tuples-only --no-align -c "$QUERY"
          EOS
            kubectl -n "$ns" cp "$tmp" "$pod":/tmp/run-sql.sh >/dev/null
            rm -f "$tmp"
            kubectl -n "$ns" exec "$pod" -- bash -lc "chmod +x /tmp/run-sql.sh; QUERY=\"$q\" /tmp/run-sql.sh; rm -f /tmp/run-sql.sh"
          }
          EOF

      - name: Query ID range from Database
        id: query
        env:
          # If scheduled look back 2 hours, otherwise use input values
          HOURS: ${{ inputs.hours }}
          ENV: ${{ steps.vars.outputs.env }}
          NS:  ${{ steps.vars.outputs.ns }}
        run: |
          set -euo pipefail
          source helpers.sh

          get_window() {
            sql_in_utils "$NS" "select min(n.id) as min_id, max(n.id)+1 as max_id, count(*) as node_count
            from alf_node n 
            join alf_store s on s.id = n.store_id 
            where n.audit_created > (now() - interval '${HOURS} hour')::timestamptz::text 
            and s.protocol = 'workspace' 
            and s.identifier = 'SpacesStore';"
          }

          parse_row() { IFS='|' read -r a b c <<<"$1"; echo "$a $b $c"; }

          row="$(get_window)" || { echo "Failed to compute batch window" >&2; exit 1; }

          read from_id to_id node_count <<<"$(parse_row "$row")"
          
          # if no rows found, exit
          if [[ -z "$node_count" || "$node_count" -eq 0 ]]; then
            echo "No new rows in the last ${HOURS} hours (to_id=${to_id}). Done."
            break
          else
            echo "Run batch: FROM=${from_id} TO=${to_id} (count=${node_count})"
            task reindex_by_id ENV="${ENV}" FROM="${from_id}" TO="${to_id}"
          fi
